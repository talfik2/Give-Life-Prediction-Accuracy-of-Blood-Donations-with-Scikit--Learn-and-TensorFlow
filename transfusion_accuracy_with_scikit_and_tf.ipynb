{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_646/img/blood_donation.png\" style=\"float: right;\" alt=\"A pictogram of a blood bag with blood donation written in it\" width=\"200\"></p>\n",
    "<p>Blood transfusion saves lives - from replacing lost blood during major surgery or a serious injury to treating various illnesses and blood disorders. Ensuring that there's enough blood in supply whenever needed is a serious challenge for the health professionals. According to <a href=\"https://www.webmd.com/a-to-z-guides/blood-transfusion-what-to-know#1\">WebMD</a>, \"about 5 million Americans need a blood transfusion every year\".</p>\n",
    "<p>Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive. We want to predict whether or not a donor will give blood the next time the vehicle comes to campus.</p>\n",
    "<p>The data is stored in <code>datasets/transfusion.data</code> and it is structured according to RFMTC marketing model (a variation of RFM). We'll explore what that means later in this notebook. First, let's inspect the data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the blood donations data\n",
    "<p>We now know that we are working with a typical CSV file (i.e., the delimiter is <code>,</code>, etc.). We proceed to loading the data into memory.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>whether he/she donated blood in March 2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50                  12500             98   \n",
       "1                 0                 13                   3250             28   \n",
       "2                 1                 16                   4000             35   \n",
       "3                 2                 20                   5000             45   \n",
       "4                 1                 24                   6000             77   \n",
       "\n",
       "   whether he/she donated blood in March 2007  \n",
       "0                                           1  \n",
       "1                                           1  \n",
       "2                                           1  \n",
       "3                                           1  \n",
       "4                                           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Reading in dataset\n",
    "transfusion = pd.read_csv(\"C:\\\\Users\\\\talfi\\\\python\\\\pred\\\\pred1\\\\pred2\\\\pred.data\")\n",
    "\n",
    "# Printing out the first rows of our dataset\n",
    "transfusion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspecting transfusion DataFrame\n",
    "<p>Let's briefly return to our discussion of RFM model. RFM stands for Recency, Frequency and Monetary Value and it is commonly used in marketing for identifying your best customers. In our case, our customers are blood donors.</p>\n",
    "<p>RFMTC is a variation of the RFM model. Below is a description of what each column means in our dataset:</p>\n",
    "<ul>\n",
    "<li>R (Recency - months since the last donation)</li>\n",
    "<li>F (Frequency - total number of donation)</li>\n",
    "<li>M (Monetary - total blood donated in c.c.)</li>\n",
    "<li>T (Time - months since the first donation)</li>\n",
    "<li>a binary variable representing whether he/she donated blood in March 2007 (1 stands for donating blood; 0 stands for not donating blood)</li>\n",
    "</ul>\n",
    "<p>It looks like every column in our DataFrame has the numeric type, which is exactly what we want when building a machine learning model. Let's verify our hypothesis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 5 columns):\n",
      " #   Column                                      Non-Null Count  Dtype\n",
      "---  ------                                      --------------  -----\n",
      " 0   Recency (months)                            748 non-null    int64\n",
      " 1   Frequency (times)                           748 non-null    int64\n",
      " 2   Monetary (c.c. blood)                       748 non-null    int64\n",
      " 3   Time (months)                               748 non-null    int64\n",
      " 4   whether he/she donated blood in March 2007  748 non-null    int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 29.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Print a concise summary of transfusion DataFrame\n",
    "transfusion.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating blood_donation column\n",
    "<p>We are aiming to predict the value in <code>whether he/she donated blood in March 2007</code> column. Let's rename this it to <code>blood_donation</code> so that it's more convenient to work with.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>blood_donation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50                  12500             98   \n",
       "1                 0                 13                   3250             28   \n",
       "\n",
       "   blood_donation  \n",
       "0               1  \n",
       "1               1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename whether he/she donated blood in March 2007 column as 'blood_donation' for brevity \n",
    "transfusion.rename(\n",
    "    columns={'whether he/she donated blood in March 2007': 'blood_donation'},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Print out the first 2 rows\n",
    "transfusion.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Checking blood_donation incidence\n",
    "<p>We want to predict whether or not the same donor will give blood the next time the vehicle comes to campus. The model for this is a binary classifier, meaning that there are only 2 possible outcomes:</p>\n",
    "<ul>\n",
    "<li><code>0</code> - the donor will not give blood</li>\n",
    "<li><code>1</code> - the donor will give blood</li>\n",
    "</ul>\n",
    "<p>blood_donation incidence is defined as the number of cases of each individual value in a dataset. That is, how many 0s in the blood_donation column compared to how many 1s? blood_donation incidence gives us an idea of how balanced (or imbalanced) is our dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.762\n",
       "1    0.238\n",
       "Name: blood_donation, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print target incidence proportions, rounding output to 3 decimal places\n",
    "transfusion.blood_donation.value_counts(normalize = True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCIKIT LEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Splitting transfusion into train and test datasets\n",
    "<p>We'll now use <code>train_test_split()</code> method to split <code>transfusion</code> DataFrame.</p>\n",
    "<p>blood_donation incidence informed us that in our dataset <code>0</code>s appear 76% of the time. We want to keep the same structure in train and test datasets, i.e., both datasets must have 0 target incidence of 76%. This is very easy to do using the <code>train_test_split()</code> method from the <code>scikit learn</code> library - all we need to do is specify the <code>stratify</code> parameter. In our case, we'll stratify on the <code>blood_donation</code> column.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1750</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)\n",
       "334                16                  2                    500             16\n",
       "99                  5                  7                   1750             26"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import train_test_split method\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split transfusion DataFrame into\n",
    "# X_train, X_test, y_train and y_test datasets,\n",
    "# stratifying on the `blood_donation` column\n",
    "X_train, X_test, y_train ,y_test = train_test_split(\n",
    "    transfusion.drop(columns='blood_donation'),\n",
    "    transfusion.blood_donation,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=transfusion.blood_donation\n",
    ")\n",
    "\n",
    "# Print out the first 2 rows of X_train\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Accuracy Score with Sckit - Learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to train and test our M.L. model's accuracy. <br>\n",
    "I'll first fit our model to Logistic Regression by  `sklearn.linear_model` 's `LogisticRegression` <br>\n",
    "Then, I'll train our ML model by `.score()` method <br>\n",
    "After that, I'll test our ML model  again by `.score()` method. To test our model, I could use `sklearn.metrics`'s`accuracy_score` but both of them do the same thing is by inspecting the SK Learn source code. Turns out that the `.score()` method in the LogisticRegression class directly calls the `sklearn.metrics.accuracy_score` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7736185383244206"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "reg_all = LogisticRegression()\n",
    "# Fitting our model to Logistic Regression\n",
    "reg_all.fit(X_train, y_train)\n",
    "# Training our model\n",
    "reg_all.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7700534759358288"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing our model\n",
    "reg_all.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model's accuracy is **0.7700534759358288** Now, let's do the same steps with the TensorFlow and find out which library provides better accuracy for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TENSORFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Renaming Column Names for Better Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfusion = transfusion.rename(columns={\"Recency (months)\":\"Recency-months\", \"Frequency (times)\":\"Frequency-times\", \"Monetary (c.c. blood)\":\"Monetary-cc-blood\",\"Time (months)\":\"Time-months\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Splitting our data into Training and Evaluation parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = transfusion.iloc[0:449,:] # 60 % of our dataset is splitted by training set\n",
    "evaldata = transfusion.iloc[449:748, :] # 40 % of our dataset is splitted by eval set\n",
    "ytrain = traindata.pop(\"blood_donation\")\n",
    "yeval = evaldata.pop(\"blood_donation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Creating Input Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am creating input functions to supply data for training, evaluating, and prediction.<br>\n",
    "\n",
    "An input function is a function that returns a tf.data.Dataset object which outputs the following two-element tuple:\n",
    "\n",
    "* features - A Python dictionary in which:<br>\n",
    "Each key is the name of a feature. <br>\n",
    "Each value is an array containing all of that feature's values.\n",
    "* label - An array containing the values of the label for every example. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_evaluation_set():\n",
    "    features = {0:0,\n",
    "               1:1}\n",
    "    labels = np.array([1, 1])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    \n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "        \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Defining the Feature Columns\n",
    "\n",
    "A feature column is an object describing how the model should use raw input data from the features dictionary. When I build an Estimator model, I pass it a list of feature columns that describes each of the features you want the model to use. The tf.feature_column module provides many options for representing data to the model.\n",
    "\n",
    "For transfusion data, the 2 raw features are numeric values, so we'll build a list of feature columns to tell the Estimator model to represent each of the four features as 32-bit floating-point values. Therefore, the code to create the feature column is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in traindata.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key = key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the description of how I want the model to represent the raw features, I can build the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Instantiate an estimator\n",
    "___\n",
    "The Transfusion problem is a classic classification problem. Fortunately, TensorFlow provides several pre-made classifier Estimators, including:\n",
    "\n",
    "* `tf.estimator.DNNClassifier` for deep models that perform multi-class classification.\n",
    "* `tf.estimator.DNNLinearCombinedClassifier` for wide & deep models.\n",
    "* `tf.estimator.LinearClassifier` for classifiers based on linear models. <br>\n",
    "For this problem, `tf.estimator.DNNClassifier` seems like the best choice. Here's how I instantiated this Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\talfi\\AppData\\Local\\Temp\\tmpakh71z17\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\talfi\\\\AppData\\\\Local\\\\Temp\\\\tmpakh71z17', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Building a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=my_feature_columns,\n",
    "                                      # Two hidden layers of 30 and 10 nodes respectively.\n",
    "                                      hidden_units =[30, 10],\n",
    "                                       # The model must choose between 3 classes.\n",
    "                                       n_classes =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, Evaluate, and Predict\n",
    "___\n",
    "Now that I have an Estimator object, I can call methods to do the following:\n",
    "\n",
    "* Train the model.\n",
    "* Evaluate the trained model.\n",
    "* Use the trained model to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\talfi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\talfi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\adagrad.py:82: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\talfi\\AppData\\Local\\Temp\\tmpakh71z17\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 34.921375, step = 0\n",
      "INFO:tensorflow:global_step/sec: 414.142\n",
      "INFO:tensorflow:loss = 0.711242, step = 100 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.928\n",
      "INFO:tensorflow:loss = 0.68018097, step = 200 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.191\n",
      "INFO:tensorflow:loss = 0.75355935, step = 300 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.298\n",
      "INFO:tensorflow:loss = 0.6628117, step = 400 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.86\n",
      "INFO:tensorflow:loss = 0.66655564, step = 500 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.177\n",
      "INFO:tensorflow:loss = 0.6330796, step = 600 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.315\n",
      "INFO:tensorflow:loss = 0.68950236, step = 700 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.493\n",
      "INFO:tensorflow:loss = 0.69817626, step = 800 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.852\n",
      "INFO:tensorflow:loss = 0.57382274, step = 900 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.901\n",
      "INFO:tensorflow:loss = 0.6505656, step = 1000 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.648\n",
      "INFO:tensorflow:loss = 0.62219006, step = 1100 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.848\n",
      "INFO:tensorflow:loss = 0.6192003, step = 1200 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 576.913\n",
      "INFO:tensorflow:loss = 0.589656, step = 1300 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.946\n",
      "INFO:tensorflow:loss = 0.65387654, step = 1400 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.177\n",
      "INFO:tensorflow:loss = 0.56430084, step = 1500 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.069\n",
      "INFO:tensorflow:loss = 0.5539603, step = 1600 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.17\n",
      "INFO:tensorflow:loss = 0.65114355, step = 1700 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.383\n",
      "INFO:tensorflow:loss = 0.5553552, step = 1800 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.296\n",
      "INFO:tensorflow:loss = 0.5633621, step = 1900 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 573.04\n",
      "INFO:tensorflow:loss = 0.5804013, step = 2000 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.761\n",
      "INFO:tensorflow:loss = 0.589315, step = 2100 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 571.754\n",
      "INFO:tensorflow:loss = 0.58521664, step = 2200 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 562.12\n",
      "INFO:tensorflow:loss = 0.58657324, step = 2300 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 568.512\n",
      "INFO:tensorflow:loss = 0.58225965, step = 2400 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 562.121\n",
      "INFO:tensorflow:loss = 0.5686181, step = 2500 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 558.98\n",
      "INFO:tensorflow:loss = 0.54491794, step = 2600 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.835\n",
      "INFO:tensorflow:loss = 0.55813694, step = 2700 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 611.391\n",
      "INFO:tensorflow:loss = 0.5268518, step = 2800 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.047\n",
      "INFO:tensorflow:loss = 0.53422415, step = 2900 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 611.553\n",
      "INFO:tensorflow:loss = 0.489049, step = 3000 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.908\n",
      "INFO:tensorflow:loss = 0.54078007, step = 3100 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 550.442\n",
      "INFO:tensorflow:loss = 0.55856895, step = 3200 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.385\n",
      "INFO:tensorflow:loss = 0.4964916, step = 3300 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.64\n",
      "INFO:tensorflow:loss = 0.57713926, step = 3400 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.766\n",
      "INFO:tensorflow:loss = 0.5367444, step = 3500 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.305\n",
      "INFO:tensorflow:loss = 0.509272, step = 3600 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.576\n",
      "INFO:tensorflow:loss = 0.57274264, step = 3700 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.273\n",
      "INFO:tensorflow:loss = 0.52768505, step = 3800 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 560.725\n",
      "INFO:tensorflow:loss = 0.5272786, step = 3900 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.998\n",
      "INFO:tensorflow:loss = 0.49180597, step = 4000 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.739\n",
      "INFO:tensorflow:loss = 0.48616046, step = 4100 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.86\n",
      "INFO:tensorflow:loss = 0.4716619, step = 4200 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.18\n",
      "INFO:tensorflow:loss = 0.56313616, step = 4300 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.067\n",
      "INFO:tensorflow:loss = 0.518056, step = 4400 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.595\n",
      "INFO:tensorflow:loss = 0.5094391, step = 4500 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.82\n",
      "INFO:tensorflow:loss = 0.5156698, step = 4600 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.189\n",
      "INFO:tensorflow:loss = 0.5653143, step = 4700 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 567.563\n",
      "INFO:tensorflow:loss = 0.5365474, step = 4800 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 562.437\n",
      "INFO:tensorflow:loss = 0.53451544, step = 4900 (0.179 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\talfi\\AppData\\Local\\Temp\\tmpakh71z17\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.48880613.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1fd36a73880>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model\n",
    "classifier.train(input_fn = lambda: input_fn(traindata, ytrain, training=True),\n",
    "                steps = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Loss = 0.48` = The less the loss is better for us, and 0.48 is a good starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrap up my `input_fn` call in a lambda to capture the arguments while providing an input function that takes no arguments, as expected by the Estimator. The `steps` argument tells the method to stop training after a number of training steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Evaluating the Model\n",
    "Now that the model has been trained, I can get some statistics on its performance. The following code block evaluates the accuracy of the trained model on the test data: <br>\n",
    "As I'll evaluate my data, I'll set `training = False` and use `evaldata`and `yeval` for the `classifier.evaluate` function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-02-01T04:25:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\talfi\\AppData\\Local\\Temp\\tmpakh71z17\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.76304s\n",
      "INFO:tensorflow:Finished evaluation at 2021-02-01-04:25:32\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.80936456, accuracy_baseline = 0.78929764, auc = 0.78897643, auc_precision_recall = 0.53606206, average_loss = 0.4223799, global_step = 5000, label/mean = 0.21070234, loss = 0.34025657, precision = 0.6666667, prediction/mean = 0.22000127, recall = 0.1904762\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\talfi\\AppData\\Local\\Temp\\tmpakh71z17\\model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(evaldata, yeval, training = False))\n",
    "\n",
    "print(\"\\nTest set accuracy: {accuracy:0.3f}\\n\".format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result is **0.809** with TensorFlow. <br>It is **0.770** with Scikit-Learn. <br> Our accuracy is increased **3.9 %** . It may seem a little change, but for M.L. models, even little changes can create big differences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
